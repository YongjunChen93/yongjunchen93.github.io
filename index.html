<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <style>
      body {
          font-family: 'Helvetica', sans-serif;
          <!-- background-image: url("./images/bg.jpg");
          background-position: center top;
          background-size: 1300px, 280px;
          background-repeat: no-repeat;
          -->
      }
    </style>

    <title>Yongjun Chen </title>
    <!-- copied this email-hiding script from Silias Boyd-Wickizer
                  https://pdos.csail.mit.edu/~sbw/ -->
    <script type="text/javascript">
      function toggle_abstract(elem) {
        var as = elem.parentNode.parentNode.getElementsByClassName("abstract");
        if (as.length > 0) {
          var a = as[0];
          a.className = "abstract-show"
        }
        else {
          as = elem.parentNode.parentNode.getElementsByClassName("abstract-show");
          var a = as[0];
          a.className = "abstract"
        }
      }
    </script>
    
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
    </script>
    <style>
      .abstract {
        display: none;
      }
      .abstract-show {
        margin: 10px;
        padding: 7px;
        border: 1px dotted #A09040;
        text-align: justify;
      }
    </style>
  </head>

  <body>
    <h1>Yongjun Chen</h1>
    <table class="imgtable", style="color:black;"><tr><td>
      <img style="" src="images/selfie.jpg" alt="photography" width="160px" height="160px"/>&nbsp;</td>
      <td align="left">
        <p><font><strong>About Me:</font></strong> I am currently a Senior Research Engineer at <a href="https://einstein.ai/">Salesforce Research</a>. I am interested in research and productizing machine learning solutions to solve real-world problems. Currently, I work on Recommender Systems, Applied Machine Learning, and AutoML. I obtained my M.S. degree from Computer Science department at Washington State University, advised by <a href="http://people.tamu.edu/~sji/">Prof. Shuiwang Ji</a>. Before that, I got my bachelor’s degree from Mathematics and Statistics department at Huazhong University of Science and Technology (HUST) in China. <br/>

      <br/><font><strong>Contact:</font></strong> <a style="color:black;" href="mailto:yongjun.chen@salesforce.com">yongjun.chen@salesforce.com</a>
      <!-- Phone: 509-339-9024<br/> -->
      <!-- Address: 124 University Ave, Palo Alto, CA, 94301<br/> -->
      
      <br/><a href="https://www.linkedin.com/in/YongjunChen/"><br/>[Linkedin]</a>
      <a href="https://scholar.google.com/citations?user=XixFvLIAAAAJ&hl=en">[Google Scholar]</a>
      <a href="https://github.com/YongjunChen93">[Github]</a>
      <!-- <a href="https://github.com/YChen1993">[Github2]</a> -->
      </td></tr>
    </table>


    <h2>Publications</h2>
    (* denotes equal contribution)

      <h3>Conference</h3>
      <table class="imgtable"><tr><td>
        <!-- <img src="images/AAAI19.jpg" alt="photography" width="300px" height="120px" />&nbsp; -->
      </td>
        <td align="left", style="line-height:20px;"><font size="4.0px"><strong>ELECRec: Training Sequential Recommenders as Discriminators</strong><br></font>
        <font><I>Yongjun Chen, Jia Li, Caiming Xiong<br></I></font> 
        <font>The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval <strong>(SIGIR)</strong>, 2022</font>
        <div class="links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/pdf/2204.02011.pdf">Paper</a>]
          [<a href="https://github.com/YChen1993/ELECRec">Code</a>]
        <div class="abstract", style="line-height:20px">
          Sequential recommendation is often considered as a generative
          task, i.e., training a sequential encoder to generate the next item of
          a user’s interests based on her historical interacted items. Despite
          their prevalence, these methods usually require training with more
          meaningful samples to be effective, which otherwise will lead to
          a poorly trained model. In this work, we propose to train the sequential 
          recommenders as discriminators rather than generators.
          Instead of predicting the next item, our method trains a discriminator 
          to distinguish if a sampled item is a ‘real’ target item or not. 
          A generator, as an auxiliary model, is trained jointly with the discriminator 
          to sample plausible alternative next items and will be thrown
          out after training. The trained discriminator is considered as the
          final SR model and denoted as ELECRec. Experiments conducted
          on four datasets demonstrate the effectiveness and efficiency of the
          proposed approach.
        </div>
      </td></tr></table>

      <table class="imgtable"><tr><td>
        <!-- <img src="images/AAAI19.jpg" alt="photography" width="300px" height="120px" />&nbsp; -->
      </td>
        <td align="left", style="line-height:20px;"><font size="4.0px"><strong>Intent Contrastive Learning for Sequential Recommendation</strong><br></font>
        <font><I>Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, Caiming Xiong<br></I></font> 
        <font>The Web Conference <strong>(WWW)</strong>, 2022</font>
        <div class="links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/pdf/2202.02519.pdf">Paper</a>]
          [<a href="https://github.com/salesforce/ICLRec">Code</a>]
        <div class="abstract", style="line-height:20px">
          Users’ interactions with items are driven by various intents (e.g., preparing for holiday gifts, shopping for fishing equipment, etc.). However, users’ underlying intents are often unobserved/latent,making it challenging to leverage such a latent intent factor for Sequential recommendation(SR). To investigate the benefits of latent intent and leverage it effectively for recommendation, we proposeIntentContrastiveLearning(ICL), a general learning paradigm that leverages a latent intent variable into SR. The core idea is to learn users’ intent distribution functions from unlabeled user behavior sequences and optimize SR models with contrastive self-supervised learning (SSL) by considering the learnt intents to improve recommendation. Specifically, we introduce a latent variable to represent users’ intents and learn the distribution function of the latent variable via clustering. We propose to leverage the learnt intents intoSR models via contrastive SSL, which maximizes the agreement between a view of sequence and its corresponding intent. The training is alternated between intent representation learning and the SR model optimization steps within the generalized expectation-maximization (EM) framework. Fusing user intent information intoSR also improves model robustness. Experiments conducted on four real-world datasets demonstrate the superiority of the proposed learning paradigm, which improves performance, and robustness against data sparsity and noisy interaction issues. Case studies onSports and Yelp further verify the effectiveness of ICL.</div>
      </td></tr></table>

      <table class="imgtable"><tr><td>
        <!-- <img src="images/AAAI19.jpg" alt="photography" width="300px" height="120px" />&nbsp; -->
      </td>
        <td align="left", style="line-height:20px;"><font size="4.0px"><strong>Modeling Dynamic Attributes for Next Basket Recommendation</strong><br></font>
        <font><I>Yongjun Chen, Jia Li, Chenghao Liu, Chenxi Li, Markus Anderle, Julian McAuley, Caiming Xiong<br></I></font> 
        <font>Context-Aware Recommender Systems Workshop at ACM Conference on Recommender Systems <strong>(CARS@RecSys)</strong>, 2021</font>
        <div class="links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/pdf/2109.11654.pdf">Paper</a>]
          [<a href="https://github.com/YChen1993/AnDa">Code</a>]
        <div class="abstract", style="line-height:20px">
          Traditional approaches to next-item and next basket recommendation typically extract users’ interests based on their past interactions and associated static contextual information (e.g. a user id or item category). However, extracted interests can be inaccurate and become obsolete. Dynamic attributes, such as user income changes, item price changes (etc.), change over time. Such dynamics can intrinsically reflect the evolution of users’ interests. We argue that modeling such dynamic attributes can boost recommendation performance. However, properly integrating them into user interest models is challenging since attribute dynamics can be diverse such as time-interval aware, periodic patterns (etc.), and they represent users’ behaviors from different perspectives, which can happen asynchronously with interactions. Besides dynamic attributes, items in each basket contain complex interdependencies which might be beneficial but nontrivial to effectively capture. To address these challenges, we propose a novel Attentive network to model Dynamic attributes (named AnDa). AnDa separately encodes dynamic attributes and basket item sequences. We design a periodic aware encoder to allow the model to capture various temporal patterns from dynamic attributes. To effectively learn useful item relationships, intra-basket attention module is proposed. Experimental results on three real-world datasets demonstrate that our method consistently outperforms the state-of-the-art.</div>
      </td></tr></table>

      <table class="imgtable"><tr><td>
        <!-- <img src="images/AAAI19.jpg" alt="photography" width="300px" height="120px" />&nbsp; -->
      </td>
        <td align="left", style="line-height:20px;"><font size="4.0px"><strong>Interpreting Deep Models for Text Analysis via Optimization and Regularization Methods</strong><br></font>
        <font><I>Hao Yuan, Yongjun Chen</font>, Xia Hu and Shuiwang Ji<br></I></font> 
        <font>The 33rd AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong>, 2019</font>
        <div class="links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://ojs.aaai.org//index.php/AAAI/article/view/4517">Paper</a>]
        <div class="abstract", style="line-height:20px">
          Interpreting deep neural networks is of great importance to
          understand and verify deep models for natural language processing
          (NLP) tasks. However, most existing approaches only
          focus on improving the performance of models but ignore
          their interpretability. In this work, we propose an approach to
          investigate the meaning of hidden neurons of convolutional
          neural network (CNN) models.We first employ saliency map
          and optimization techniques to approximate the detected information
          of hidden neurons from input sentences. Then we
          develop regularization terms and explore words in vocabulary
          to interpret such detected information. Experimental results
          demonstrate that our approach can identify meaningful and
          reasonable interpretations for hidden spatial locations. Additionally,
          we show that our approach can describe the decision
          procedure of deep NLP models.</div>
      </td></tr></table>

      <table class="imgtable"><tr><td>
        <!-- <img src="images/WWW19.png" alt="photography" width="300px" height="120px" />&nbsp; -->
      </td>
        <td align="left", style="line-height:20px;"><font size="4.0px"><strong>Learning Graph Pooling and Hybrid Convolutional Operations for Text Representations</strong><br></font>
        <font><I>Hongyang Gao, Yongjun Chen</font>, and Shuiwang Ji<br></I></font> 
        <font>The Web Conference <strong>(WWW)</strong>, 2019</font>
        <div class="links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/pdf/1901.06965.pdf">Paper</a>]
        <div class="abstract", style="line-height:20px">With the development of graph convolutional networks (GCN), deep learning methods have started to be used on graph data. In additional
          to convolutional layers, pooling layers are another important components
          of deep learning. However, no effective pooling methods
          have been developed for graphs currently. In this work, we propose
          the graph pooling (gPool) layer, which employs a trainable
          projection vector to measure the importance of nodes in graphs. By
          selecting the k-most important nodes to form the new graph, gPool
          achieves the same objective as regular max pooling layers operating
          on images. Another limitation of GCN when used on graph-based
          text representation tasks is that, GCNs do not consider the order
          information of nodes in graph. To address this limitation, we propose
          the hybrid convolutional (hConv) layer that combines GCN
          and regular convolutional operations. The hConv layer is capable of
          increasing receptive fields quickly and computing features automatically.
          Based on the proposed gPool and hConv layers, we develop
          new deep networks for text categorization tasks. Our results show
          that the networks based on gPool and hConv layers achieves new
          state-of-the-art performance as compared to baseline methods.</div>
      </td></tr></table>

      <table class="imgtable"><tr><td>
      <!--   <img src="images/architecture.png" alt="photography" width="300px" height="150px" />&nbsp; -->
      </td>
        <td align="left", style="line-height:20px;"><font size="4.0px"><strong>Dense Transformer Networks</strong><br></font>
        <font><I>Jun Li, <font>Yongjun Chen</font>, Lei Cai, Ian Davidson, and Shuiwang Ji<br></I></font> 
        <font>The 28th International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong>, 2019</font>
        <div class="links">[<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/abs/1705.08881">Paper</a>]
          [<a href="https://github.com/divelab/dtn">Code</a>]</div>
        <div class="abstract", style="line-height:20px">The key idea of current deep learning methods for dense prediction is to apply a model on a regular patch centered on each pixel to make pixel-wise predictions. These methods are limited in the sense that the patches are determined by network architecture instead of learned from data. In this work, we propose the dense transformer networks, which can learn the shapes and sizes of patches from data. The dense transformer networks employ an encoder-decoder architecture, and a pair of dense transformer modules are inserted into each of the encoder and decoder paths. The novelty of this work is that we provide technical solutions for learning the shapes and sizes of patches from data and efficiently restoring the spatial correspondence required for dense prediction. The proposed dense transformer modules are differentiable, thus the entire network can be trained. We apply the proposed networks on natural and biological image segmentation tasks and show superior performance is achieved in comparison to baseline methods.</div>
          </td></tr>
      </table>

        <table class="imgtable"><tr><td>
<!--           <img src="images/voxeldeconvolution.png" alt="photography" width="300px" height="150px" />&nbsp; -->
          </td>
          <td align="left", style="line-height:20px;"><font size="4.0px"><strong>Voxel Deconvolutional Networks for 3D Brain Image Labeling</strong><br></font>
          <font><I>Yongjun Chen</font>, Hongyang Gao, Lei Cai, Min Shi, Dinggang Shen and Shuiwang Ji<br></I></font> 
          <font>The 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining <strong>(KDD)</strong>, 2018</font>
          <div class="links">[<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
            [<a href="http://delivery.acm.org/10.1145/3220000/3219974/p1226-chen.pdf?ip=69.166.46.137&id=3219974&acc=OPENTOC&key=B63ACEF81C6334F5%2E3B1D11B7501B70D8%2E4D4702B0C3E38B35%2E054E54E275136550&__acm__=1535680435_e69225cf8c7ed216e2e0a11ee85f4452">Paper</a>]
            [<a href="https://github.com/divelab/VoxelDCN">Code</a>]
            [<a href="https://www.eecs.wsu.edu/~ychen3/kdd_slides_vdn.pdf">Slides</a>]
            [<a href="https://www.eecs.wsu.edu/~ychen3/kdd_poster_vdn.pdf">Poster</a>]</div>
          <div class="abstract", style="line-height:20px">Deep learning methods have shown great success in pixel-wise
            prediction tasks. One of the most popular methods employs an
            encoder-decoder network in which deconvolutional layers are used
            for up-sampling feature maps. However, a key limitation of the
            deconvolutional layer is that it suers from the checkerboard artifact
            problem, which harms the prediction accuracy. is is caused
            by the independency among adjacent pixels on the output feature
            maps. Previous work only solved the checkerboard artifact issue of
            deconvolutional layers in the 2D space. Since the number of intermediate
            feature maps needed to generate a deconvolutional layer
            grows exponentially with dimensionality, it is more challenging to
            solve this issue in higher dimensions. In this work, we propose the
            voxel deconvolutional layer (VoxelDCL) to solve the checkerboard
            artifact problem of deconvolutional layers in 3D space. We also
            provide an ecient approach to implement VoxelDCL. To demonstrate
            the eectiveness of VoxelDCL, we build four variations of
            voxel deconvolutional networks (VoxelDCN) based on the U-Net
            architecture with VoxelDCL. We apply our networks to address
            volumetric brain images labeling tasks using the ADNI and LONI
            LPBA40 datasets. e experimental results show that the proposed
            iVoxelDCNa achieves improved performance in all experiments.
            It reaches 83.34% in terms of dice ratio on the ADNI dataset and
            79.12% on the LONI LPBA40 dataset, which increases 1.39% and
            2.21% respectively compared with the baseline. In addition, all the
            variations of VoxelDCN we proposed outperform the baseline methods
            on the above datasets, which demonstrates the eectiveness of
            our methods.</div>
          </td></tr>
      </table>
     <h3>Preprints</h3>

      <table class="imgtable"><tr><td>
        <!-- <img src="images/AAAI19.jpg" alt="photography" width="300px" height="120px" />&nbsp; -->
      </td>
        <td align="left", style="line-height:20px;"><font size="4.0px"><strong>Contrastive Self-supervised Sequential Recommendation with Robust Augmentation</strong><br></font>
        <font><I>Zhiwei Liu*, Yongjun Chen*, Jia Li, Philip S. Yu, Julian McAuley, Caiming Xiong</I><br></font> 
        <font>Preprint, 2021</font>
        <div class="links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/pdf/2108.06479.pdf">Paper</a>]
          [<a href="https://github.com/YChen1993/CoSeRec">Code</a>]
        <div class="abstract", style="line-height:20px">
          Sequential Recommendation describes a set of techniques to model
          dynamic user behavior in order to predict future interactions in sequential user data. At their core, such approaches model transition probabilities between items in a sequence, whether through Markov chains, recurrent networks, or more recently, Transformers. However both old and new issues remain, including data-sparsity and noisy data; such issues can impair performance, especially in complex, parameter-hungry models. In this paper, we investigate the application of contrastive Self-Supervised Learning (SSL) to sequential recommendation, as a way to alleviate some of these issues. Contrastive SSL constructs augmentations from unlabelled instances, where agreements among positive pairs are maximized. It is challenging to devise a contrastive SSL framework for sequential recommendation, due to its discrete nature, correlations among items, and skewness of length distributions. To this end, we propose a novel framework, Contrastive Self-supervised Learning for Sequential Recommendation (CoSeRec). We introduce two informative augmentation operators leveraging item correlations to create high quality views for contrastive learning. Experimental results on three real-world datasets demonstrate the effectiveness of the proposed method on improving model performance, and the robustness against sparse and noisy data. Our implementation is available: https://github.com/YChen1993/CoSeRec.</div>
      </td></tr></table>


    <h2>Honors & Awards</h2>
        <ul>
        <li><p>Pennyworth@Salesforce is ranked #4 of 
        <a href="https://algo.browser.qq.com/#en">CIKM 2021 AnalytiCup on Automated Hyperparameter Optimization</a> (led the competition), Oct. 2021.</p>
        </li>
        <li><p>Excellent Graduate, HUST, June. 2016. </p>
        </li>
        <li><p>Honorable mention prize of The International Interdisciplinary Contest in Modeling (ICM), Feb. 2015.</p>
        </li>
        <li><p>
        Undergraduate Science and Technology Innovation Scholarship, HUST, Feb. 2014, 2015.</p>
        </ul>

    <h2>Teaching Experiences</h2>
      <h3>Teaching Assistant</h3>
        <font color="#676868">Washington State University, WA, USA</font> 
        <ul>
        <li><p>Spring 2018: CptS 437 Introduction to Machine Learning</p>
        </li>
        <li><p>Fall 2017: CptS 355 Programming Language Design</p>
        </li>
        <li><p>Fall 2017: CptS 440/540 Artificial Intelligence</p>
        </li>
        <li><p>Spring 2017: EE 221 Numerical Computing for Engineers</p>
        </li>
        <li><p>Spring 2017: CptS 223 Advanced Data Structures C/C++</p>
        </li>
        </ul>

  </body>
    <h2>Education</h2>
      <ul>
        <li><p>M.S., Computer Science, <a href="https://wsu.edu/">Washington State University</a>, August 2016 - Dec. 2018</p>
          <ul>
            <li>Thesis: <a href="https://rex.libraries.wsu.edu/esploro/outputs/graduate/Advanced-Deep-Learning-Methods-for-Image/99900525175901842">Advanced Deep Learning Methods for Image Pixel-Wise Prediction</a></li>
          </ul>
        </li>
        <li><p>B.S., Statistics, <a href="http://english.hust.edu.cn/">Huazhong University of Science and Technology</a>, September 2012 - June 2016</p>
        </li>
      </ul>
</html>

