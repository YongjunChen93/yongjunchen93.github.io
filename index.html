<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />

    <style>
      body {
          font-family: 'Helvetica', sans-serif;
          margin-right: 10%;
          margin-left: 3%;
      }
    </style>

    <title>Yongjun Chen </title>

    <!-- copied this email-hiding script from Silias Boyd-Wickizer
                  https://pdos.csail.mit.edu/~sbw/ -->
    <script type="text/javascript">
      function toggle_abstract(elem) {
        var as = elem.parentNode.parentNode.getElementsByClassName("abstract");
        if (as.length > 0) {
          var a = as[0];
          a.className = "abstract-show"
        }
        else {
          as = elem.parentNode.parentNode.getElementsByClassName("abstract-show");
          var a = as[0];
          a.className = "abstract"
        }
      }
    </script>

    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
    </script>

    <style>
      .abstract { display: none; }
      .abstract-show {
        margin: 10px 0 0 0;
        padding: 7px;
        border: 1px dotted #A09040;
        text-align: justify;
      }
    </style>

    <!-- ✅ NEW: Papers grid layout (border only wraps image) -->
    <style>
    /* ===== Blogs: text-only cards ===== */
      /* ===== Blogs: text-only cards ===== */
      .blogs-grid{
        display: grid;
        grid-template-columns: repeat(3, minmax(0, 1fr));
        gap: 100px;
        margin-top: 20px;
        margin-bottom: 20px;
        padding: 0;
        list-style: none;
      }

      @media (max-width: 1100px){
        .blogs-grid{ grid-template-columns: repeat(2, minmax(0, 1fr)); }
      }
      @media (max-width: 700px){
        .blogs-grid{ grid-template-columns: 1fr; }
      }

      .blog-card{
        max-width: 560px;
        margin: 0;
        justify-self: start;

        min-height: 240px;
        display: flex;
        flex-direction: column;
      }

      .blog-title{
        margin: 0;
        font-weight: 800;
        line-height: 1.15;
        text-align: left;
      }

      .blog-title a{
        text-decoration: none;
        color: #111;
      }

      .blog-meta{
        display: flex;
        gap: 12px;
        font-size: 13px;
        color: #6b7280;
        margin: 10px 0 14px 0;
      }

      .blog-category,
      .blog-date{
        font-weight: 500;
        white-space: nowrap;
      }

      .blog-excerpt{
        font-size: 16px;
        line-height: 1.7;
        color: #222;
        margin: 0;

        display: -webkit-box;
        -webkit-line-clamp: 4;
        -webkit-box-orient: vertical;
        overflow: hidden;

        margin-top: 6px;
      }

      /* ===== Paper: text + image ===== */
      .papers-grid{
        display: grid;
        grid-template-columns: repeat(3, minmax(0, 1fr));
        gap: 100px;
        margin-top: 20px;
        margin-bottom: 20px;
      }

      @media (max-width: 1100px){
        .papers-grid{ grid-template-columns: repeat(2, minmax(0, 1fr)); }
      }
      @media (max-width: 700px){
        .papers-grid{ grid-template-columns: 1fr; }
      }

      /* 这个外层不加边框：只负责布局 */
      .paper-card{
        background: transparent;
      }

      /* ✅ 边框只包图片 */
      .paper-media{
        border: 1px solid #e7e7e7;
        border-radius: 12px;
        overflow: hidden;
        background: #fff;
        margin-bottom: 10px;  /* 图片边框与文字的间距 */
        max-width: 90%;
        margin-left: 0;
        margin-right: auto;
      }

      .paper-thumb{
        width: 100%;
        height: 160px;          /* 想更小：200px；想更大：240px */
        object-fit: contain;      /* “自然分割/杂志裁切” */
        display: block;
        cursor: zoom-in;
      }

      .paper-title{
        font-size: 16px;
        font-weight: 700;
        margin: 0 0 6px 0;
        line-height: 1.2;
      }

      .paper-authors{
        font-size: 13px;
        font-style: italic;
        margin: 0 0 6px 0;
        line-height: 1.25;
      }

      .paper-venue{
        font-size: 13px;
        margin: 0 0 8px 0;
        line-height: 1.25;
      }

      .paper-links{
        font-size: 13px;
        line-height: 1.25;
      }

      .paper-links a{
        text-decoration: none;
      }
    </style>
  </head>

  <script>
  document.addEventListener("DOMContentLoaded", () => {
    // Create overlay once
    const overlay = document.createElement("div");
    overlay.className = "lightbox-overlay";
    overlay.innerHTML = `<img alt="">`;
    document.body.appendChild(overlay);

    const overlayImg = overlay.querySelector("img");

    const open = (src, alt) => {
      overlayImg.src = src;
      overlayImg.alt = alt || "";
      overlay.classList.add("is-open");
      document.body.style.overflow = "hidden";
    };

    const close = () => {
      overlay.classList.remove("is-open");
      overlayImg.src = "";
      document.body.style.overflow = "";
    };

    // Click to open (delegation)
    document.addEventListener("click", (e) => {
      const img = e.target.closest("img.zoomable");
      if (!img) return;
      open(img.src, img.alt);
    });

    // Click overlay to close
    overlay.addEventListener("click", close);

    // ESC to close
    document.addEventListener("keydown", (e) => {
      if (e.key === "Escape" && overlay.classList.contains("is-open")) close();
    });
  });
  </script>

  <body>
    <h1>Yongjun Chen</h1>
    <table class="imgtable", style="color:black;"><tr><td>
      <img style="" src="images/selfie2.jpeg" alt="photography" width="160px" height="160px"/>&nbsp;</td>
      <td align="left">
        Currently a senior research engineer at <a href="https://www.apple.com/"><strong>Apple</strong></a> working on production reinforcement learning systems to align agentic models for <a href="https://www.apple.com/apple-intelligence/">Apple Intelligence</a>. <br><br>
      <font><strong>Contact:</strong></font> <a style="color:black;" href="mailto:yongjunchen1995@gmail.com">yongjunchen1995@gmail.com</a>
      <a href="https://www.linkedin.com/in/YongjunChen/">[Linkedin]</a>
      <a href="https://scholar.google.com/citations?user=XixFvLIAAAAJ&hl=en">[Google Scholar]</a>
      <a href="https://github.com/YongjunChen93">[Github]</a>
      <script>
        const isLocal = location.protocol === "file:" || location.hostname === "localhost" || location.hostname === "127.0.0.1";
        const blogLink = isLocal
          ? "http://127.0.0.1:4000/blog/"
          : "blog/";
        document.write(`<a href="${blogLink}">[Blog]</a>`);
      </script>
      </td></tr>
    </table>

    <h2><a id="blogs-link" href="blog/">Blogs</a></h2>

    <script>
      (function () {
        const a = document.getElementById("blogs-link");
        if (!a) return;
        const isFile = location.protocol === "file:";
        a.href = isFile ? "http://127.0.0.1:4000/blog/" : "blog/";
      })();
    </script>

    <ul id="blog-list" class="blogs-grid">
      <li>Loading…</li>
    </ul>

    <!-- Blogs loader -->
    <script>
    (function () {
      const container = document.getElementById("blog-list");
      if (!container) return;

      const isFile = (location.protocol === "file:");

      // ✅ 线上用相对路径（支持 GitHub Pages repo 子路径）
      const BLOG_BASE = isFile
        ? "http://127.0.0.1:4000/blog"
        : (new URL("./blog", location.href)).toString().replace(/\/$/, "");

      // ✅ cache-busting：防止浏览器执行旧版 posts.js（你现在的核心问题）
      const FEED_JS = BLOG_BASE + "/posts.js?v=" + Date.now();

      const s = document.createElement("script");
      s.src = FEED_JS;
      s.async = true;

      const stripHtml = (html) =>
        (html || "").replace(/<[^>]*>/g, "").replace(/\s+/g, " ").trim();

      const pickCategory = (p) => {
        const cats = p.categories || p.category || [];
        if (Array.isArray(cats) && cats.length) return String(cats[0]);
        if (typeof cats === "string" && cats) return cats;
        return "未分类";
      };

      const pickExcerpt = (p) => {
        const candidates = [p.excerpt, p.summary, p.description, p.content];
        for (const c of candidates) {
          const t = stripHtml(c);
          if (t) return t;
        }
        return "";
      };

      s.onload = () => {
        const posts = window.__BLOG_POSTS__;
        if (!Array.isArray(posts) || posts.length === 0) {
          container.innerHTML = "<li>No posts yet.</li>";
          return;
        }

        const limit = 9;

        container.innerHTML = posts.slice(0, limit).map((p) => {
          const href = BLOG_BASE + (p.url || "");
          const title = p.title || "Untitled";
          const date = p.date || "";
          const category = pickCategory(p);
          const excerpt = pickExcerpt(p);

          return `
            <li>
              <article class="blog-card">
                <h3 class="blog-title"><a href="${href}">${title}</a></h3>
                <div class="blog-meta">
                  <span class="blog-category">${category}</span>
                  <span class="blog-date">${date}</span>
                </div>
                <p class="blog-excerpt">${excerpt}</p>
              </article>
            </li>
          `;
        }).join("");
      };

      s.onerror = () => {
        container.innerHTML = `<li>Failed to load posts. <a href="${BLOG_BASE}/">Open blog</a></li>`;
      };

      document.head.appendChild(s);
    })();
    </script>

    <h2>Selected Papers</h2>

    <!-- ✅ NEW Papers Layout -->
    <div class="papers-grid">

      <!-- Paper 1 -->
      <div class="paper-card">
        <div class="paper-media">
          <img
            src="images/icl.png"
            alt="Intent Contrastive Learning for Sequential Recommendation"
            class="paper-thumb zoomable"
          />
        </div>

        <div class="paper-title">Intent Contrastive Learning for Sequential Recommendation, WWW@2022</div>
        <div class="paper-authors">Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, Caiming Xiong</div>

        <div class="paper-links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/pdf/2202.02519.pdf">Paper</a>]
          [<a href="https://github.com/salesforce/ICLRec">Code</a>]
        </div>

        <div class="abstract" style="line-height:20px">
          Users’ interactions with items are driven by various intents (e.g., preparing for holiday gifts, shopping for fishing equipment, etc.). However, users’ underlying intents are often unobserved/latent,making it challenging to leverage such a latent intent factor for Sequential recommendation(SR). To investigate the benefits of latent intent and leverage it effectively for recommendation, we proposeIntentContrastiveLearning(ICL), a general learning paradigm that leverages a latent intent variable into SR. The core idea is to learn users’ intent distribution functions from unlabeled user behavior sequences and optimize SR models with contrastive self-supervised learning (SSL) by considering the learnt intents to improve recommendation. Specifically, we introduce a latent variable to represent users’ intents and learn the distribution function of the latent variable via clustering. We propose to leverage the learnt intents intoSR models via contrastive SSL, which maximizes the agreement between a view of sequence and its corresponding intent. The training is alternated between intent representation learning and the SR model optimization steps within the generalized expectation-maximization (EM) framework. Fusing user intent information intoSR also improves model robustness. Experiments conducted on four real-world datasets demonstrate the superiority of the proposed learning paradigm, which improves performance, and robustness against data sparsity and noisy interaction issues. Case studies onSports and Yelp further verify the effectiveness of ICL.
        </div>
      </div>

      <!-- Paper 2 -->
      <div class="paper-card">
        <div class="paper-media">
          <img
            src="images/voxel.png"
            alt="Voxel Deconvolutional Networks for 3D Image Labeling"
            class="paper-thumb zoomable"
          />
        </div>

        <div class="paper-title">Voxel Deconvolutional Networks for 3D Image Labeling, 2018@KDD</div>
        <div class="paper-authors">Yongjun Chen, Hongyang Gao, Lei Cai, Min Shi, Dinggang Shen and Shuiwang Ji</div>
        <div class="paper-links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="http://delivery.acm.org/10.1145/3220000/3219974/p1226-chen.pdf?ip=69.166.46.137&id=3219974&acc=OPENTOC&key=B63ACEF81C6334F5%2E3B1D11B7501B70D8%2E4D4702B0C3E38B35%2E054E54E275136550&__acm__=1535680435_e69225cf8c7ed216e2e0a11ee85f4452">Paper</a>]
          [<a href="https://github.com/divelab/VoxelDCN">Code</a>]
          [<a href="https://www.eecs.wsu.edu/~ychen3/kdd_slides_vdn.pdf">Slides</a>]
          [<a href="https://www.eecs.wsu.edu/~ychen3/kdd_poster_vdn.pdf">Poster</a>]
        </div>

        <div class="abstract" style="line-height:20px">
          Deep learning methods have shown great success in pixel-wise
          prediction tasks. One of the most popular methods employs an
          encoder-decoder network in which deconvolutional layers are used
          for up-sampling feature maps. However, a key limitation of the
          deconvolutional layer is that it suffers from the checkerboard artifact
          problem, which harms the prediction accuracy. This is caused
          by the independency among adjacent pixels on the output feature
          maps. Previous work only solved the checkerboard artifact issue of
          deconvolutional layers in the 2D space. Since the number of intermediate
          feature maps needed to generate a deconvolutional layer
          grows exponentially with dimensionality, it is more challenging to
          solve this issue in higher dimensions. In this work, we propose the
          voxel deconvolutional layer (VoxelDCL) to solve the checkerboard
          artifact problem of deconvolutional layers in 3D space. We also
          provide an efficient approach to implement VoxelDCL. To demonstrate
          the effectiveness of VoxelDCL, we build four variations of
          voxel deconvolutional networks (VoxelDCN) based on the U-Net
          architecture with VoxelDCL. We apply our networks to address
          volumetric brain images labeling tasks using the ADNI and LONI
          LPBA40 datasets. The experimental results show that the proposed
          iVoxelDCNa achieves improved performance in all experiments.
          It reaches 83.34% in terms of dice ratio on the ADNI dataset and
          79.12% on the LONI LPBA40 dataset, which increases 1.39% and
          2.21% respectively compared with the baseline. In addition, all the
          variations of VoxelDCN we proposed outperform the baseline methods
          on the above datasets, which demonstrates the effectiveness of
          our methods.
        </div>
      </div>

      <!-- Paper 3 -->
      <div class="paper-card">
        <div class="paper-media">
          <img
            src="images/dtn.png"
            alt="Dense Transformer Networks"
            class="paper-thumb zoomable"
          />
        </div>

        <div class="paper-title">Dense Transformer Networks, 2019@IJCAI</div>
        <div class="paper-authors">Jun Li, Yongjun Chen, Lei Cai, Ian Davidson, and Shuiwang Ji</div>
        <div class="paper-links">
          [<a href="javascript:void(0)" onclick="toggle_abstract(this)">Abstract</a>]
          [<a href="https://arxiv.org/abs/1705.08881">Paper</a>]
          [<a href="https://github.com/divelab/dtn">Code</a>]
        </div>

        <div class="abstract" style="line-height:20px">
          The key idea of current deep learning methods for dense prediction is to apply a model on a regular patch centered on each pixel to make pixel-wise predictions. These methods are limited in the sense that the patches are determined by network architecture instead of learned from data. In this work, we propose the dense transformer networks, which can learn the shapes and sizes of patches from data. The dense transformer networks employ an encoder-decoder architecture, and a pair of dense transformer modules are inserted into each of the encoder and decoder paths. The novelty of this work is that we provide technical solutions for learning the shapes and sizes of patches from data and efficiently restoring the spatial correspondence required for dense prediction. The proposed dense transformer modules are differentiable, thus the entire network can be trained. We apply the proposed networks on natural and biological image segmentation tasks and show superior performance is achieved in comparison to baseline methods.
        </div>
      </div>

    </div>
    <!-- ✅ END Papers -->

  <h2>About Me</h2>
    <table class="imgtable", style="color:black;"><tr><td>
      <td align="left">
        <p><font>Currently a senior research engineer at <a href="https://www.apple.com/"><strong>Apple</strong></a>, where I worked on <a href="https://www.apple.com/apple-intelligence/"><strong>Apple Intelligence</strong></a> initiatives end-to-end since 2022, from early training/serving pipelines exploration to AI feature launches.<br>
        Efforts spanning benchmark training infra (e.g., jax w/ TPU vs pytorch w/ GPU) in early days, production data synthesis and mixture design, post-training and model distillation experimentation for both large and small models, and building ReAct style long-horizon reinforcement learning for aligning agentic models.<br>
        Influenced the first batches of AI feature launches including <a href="https://support.apple.com/guide/iphone/find-the-right-words-with-writing-tools-iph6f08da1d2/ios"><strong>Writing Tools</strong></a> and <a href="https://support.apple.com/guide/iphone/use-apple-intelligence-in-messages-iph64709c5c3/ios"><strong>Reply Suggestions</strong></a>.</p>

        <p>Before Apple, I was a senior research engineer at <a href="https://www.salesforceairesearch.com/"><strong>Salesforce AI Research</strong></a> (2019-2022) and worked on both research and applications of sequential recommender systems, and AutoML.</p>
      </td></tr>
    </table>

    <h3>Education</h3>
      <ul>
        <li><p>M.S., Computer Science, <a href="https://wsu.edu/">Washington State University</a>, August 2016 - Dec. 2018</p>
          <ul>
            <li>Thesis: <a href="https://rex.libraries.wsu.edu/esploro/outputs/graduate/Advanced-Deep-Learning-Methods-for-Image/99900525175901842">Advanced Deep Learning Methods for Image Pixel-Wise Prediction</a></li>
          </ul>
        </li>
        <li><p>B.S., Statistics, <a href="http://english.hust.edu.cn/">Huazhong University of Science and Technology</a>, September 2012 - June 2016</p>
        </li>
      </ul>

    <!-- <h3>DM/ML/AI Conference Reviewer</h3>
        <ul>
        <li><p>2025: COLING; 2024: TKDE, ACL, EMNLP; 2023: ACL; 2022: UAI, EMNLP, AAAI, ACML, TOIS; 2021: NAACL</p></li>
        <li><p>2020 and before: KDD, CIKM, NeurIPS, ICDM, TKDE</p></li>
        </ul> -->
  </body>
</html>
